{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "Objective:\n",
    "The goal of this notebook is to train predictive models that identify customers likely to close their credit card accounts (AttritionFlag) using the processed and feature-engineered dataset.\n",
    "\n",
    "Dataset:\n",
    "- Processed datasets: `train.csv` and `test.csv`\n",
    "\n",
    "- Features include demographic, transaction, card type, and engineered variables.\n",
    "\n",
    "- Categorical variables are already handled in the data cleaning stage.\n",
    "\n",
    "Workflow – Model Training:\n",
    "1. Load Data\n",
    "- Load `train.csv` and `test.csv`\n",
    "- Separate features (`X`) and target (`y`)\n",
    "\n",
    "2. Handle Class Imbalance\n",
    "- Apply SMOTE on the training set to balance the minority class.\n",
    "\n",
    "3. Train Classification Models\n",
    "- Train at least two models:\n",
    "  - Logistic Regression (baseline linear model)\n",
    "  - XGBoost (gradient boosting model to capture non-linearities and interactions)\n",
    "- Perform hyperparameter tuning and cross-validation to optimize each model.\n",
    "\n",
    "Next Steps:\n",
    "- The trained models will be saved and later evaluated in a separate notebook using metrics such as accuracy, precision, recall, F1-score, ROC-AUC, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths to the saved CSVs\n",
    "train_path = r'..\\..\\data\\processed\\train.csv'\n",
    "test_path  = r'..\\..\\data\\processed\\test.csv'\n",
    "\n",
    "# Load the CSVs\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "\n",
    "# Split into features and target\n",
    "X_train = train_df.drop(columns=['AttritionFlag'])\n",
    "y_train = train_df['AttritionFlag']\n",
    "\n",
    "X_test  = test_df.drop(columns=['AttritionFlag'])\n",
    "y_test  = test_df['AttritionFlag']\n",
    "\n",
    "# Optional: check shapes\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to training data\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the new class distribution\n",
    "print(\"Before SMOTE:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nAfter SMOTE:\")\n",
    "print(y_train_res.value_counts())\n",
    "\n",
    "# Optional: check shapes\n",
    "print(\"\\nX_train_res shape:\", X_train_res.shape)\n",
    "print(\"y_train_res shape:\", y_train_res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Fit scaler on training data and transform both training and test\n",
    "scaler = StandardScaler()\n",
    "X_train_res_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define Logistic Regression\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42, class_weight='balanced')\n",
    "\n",
    "# Hyperparameter candidates\n",
    "param_grid = {'C': [0.1, 1, 10]}\n",
    "\n",
    "# Stratified K-Fold\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Total number of fits\n",
    "total_fits = len(param_grid['C']) * cv.get_n_splits()\n",
    "pbar = tqdm(total=total_fits, desc=\"GridSearchCV Progress\")\n",
    "\n",
    "# Loop through hyperparameters\n",
    "for C_val in param_grid['C']:\n",
    "    lr.set_params(C=C_val)\n",
    "    # Evaluate with cross-validation using scaled features\n",
    "    scores = cross_val_score(lr, X_train_res_scaled, y_train_res, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "    results.append({\n",
    "        'C': C_val,\n",
    "        'mean_cv_roc_auc': np.mean(scores)\n",
    "    })\n",
    "    pbar.update(cv.get_n_splits())  # Update progress bar for each fold set\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# Find best hyperparameter\n",
    "best_result = max(results, key=lambda x: x['mean_cv_roc_auc'])\n",
    "best_lr = LogisticRegression(\n",
    "    C=best_result['C'], solver='lbfgs', max_iter=2000,\n",
    "    random_state=42, class_weight='balanced'\n",
    ")\n",
    "best_lr.fit(X_train_res_scaled, y_train_res)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_result)\n",
    "print(\"Best CV ROC-AUC:\", best_result['mean_cv_roc_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "best_lr = LogisticRegression(C=1, solver='lbfgs', max_iter=2000, random_state=42)\n",
    "best_lr.fit(X_train_res_scaled, y_train_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted probabilities (for ROC-AUC)\n",
    "y_pred_prob = best_lr.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Predicted class labels\n",
    "y_pred = best_lr.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(y_pred_prob, bins=20)\n",
    "plt.title(\"Predicted Probabilities for Churn\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_pred_prob))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Logistic Regression Model Evaluation — Summary\n",
    "\n",
    "**Test Results:**\n",
    "- **Accuracy:** 95.04% (misleading due to imbalance)\n",
    "- **Precision / Recall / F1-score:** 0.0 (model never predicted churn)\n",
    "- **ROC-AUC:** 0.5088 (almost random performance)\n",
    "\n",
    "**Key Takeaway:**  \n",
    "High accuracy here is misleading since the model completely fails to detect churn and has no meaningful predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------\n",
    "# Define Random Forest\n",
    "# ----------------------\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,        # number of trees\n",
    "    random_state=42,\n",
    "    class_weight='balanced', # handle imbalanced training data\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ----------------------\n",
    "# Hyperparameter candidates\n",
    "# ----------------------\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Stratified K-Fold\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Total number of fits for progress bar\n",
    "total_fits = len(param_grid['max_depth']) * len(param_grid['min_samples_split']) * cv.get_n_splits()\n",
    "pbar = tqdm(total=total_fits, desc=\"Random Forest GridSearchCV\")\n",
    "\n",
    "# ----------------------\n",
    "# Loop through hyperparameters\n",
    "# ----------------------\n",
    "for depth in param_grid['max_depth']:\n",
    "    for min_split in param_grid['min_samples_split']:\n",
    "        rf.set_params(max_depth=depth, min_samples_split=min_split)\n",
    "        scores = cross_val_score(rf, X_train_res, y_train_res, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "        results.append({\n",
    "            'max_depth': depth,\n",
    "            'min_samples_split': min_split,\n",
    "            'mean_cv_roc_auc': np.mean(scores)\n",
    "        })\n",
    "        pbar.update(cv.get_n_splits())\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# ----------------------\n",
    "# Find best hyperparameters\n",
    "# ----------------------\n",
    "best_result = max(results, key=lambda x: x['mean_cv_roc_auc'])\n",
    "best_rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=best_result['max_depth'],\n",
    "    min_samples_split=best_result['min_samples_split'],\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1\n",
    ")\n",
    "best_rf.fit(X_train_res, y_train_res)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_result)\n",
    "print(\"Best CV ROC-AUC:\", best_result['mean_cv_roc_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Predict labels\n",
    "y_pred = best_rf.predict(X_test_scaled)  # use scaled if you scaled train before\n",
    "y_pred_prob = best_rf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Random Forest Model Evaluation\n",
    "\n",
    "**Interpretation:**\n",
    "- The model predicts **only the majority class** (non-churn).\n",
    "- High accuracy is misleading.\n",
    "- Precision, Recall, and F1 are all **zero**, meaning no churn cases were identified.\n",
    "- ROC-AUC slightly above 0.5 → performance is almost random.\n",
    "- This indicates **poor predictive power**; features may not strongly correlate with churn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# Project Conclusion: Churn Prediction for Credit Card Holders\n",
    "\n",
    "## Summary of Findings\n",
    "Both **Logistic Regression** and **Random Forest** models were trained on the dataset with balanced training data (via SMOTE) and tested on the test data.\n",
    "\n",
    "### Model Performances:\n",
    "- **Accuracy**: ~95% (misleading due to class imbalance)\n",
    "- **Precision / Recall / F1-score**: All **0.0** — no churn cases were identified by either model.\n",
    "- **ROC-AUC**: ~0.51–0.52, only slightly better than random guessing.\n",
    "\n",
    "### Interpretation:\n",
    "- Despite feature engineering, tuning hyperparameters, and balancing the training data, both models defaulted to predicting only the majority class (non-churn).\n",
    "- This indicates **no strong predictive signal** in the available features to separate churn from non-churn customers.\n",
    "- High accuracy is purely a result of the majority class dominating the dataset, not actual predictive performance.\n",
    "\n",
    "## Final Conclusion\n",
    "The dataset, in its current form, **does not contain sufficient or relevant features** to build a model that can reliably predict customer attrition/churn.  \n",
    "Future work should focus on **collecting richer, more behaviorally informative features** and possibly **reshaping the problem definition** before applying predictive modeling.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creditcard-env",
   "language": "python",
   "name": "creditcard-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
