{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "Objective:\n",
    "The goal of this notebook is to train predictive models that identify customers likely to close their credit card accounts (AttritionFlag) using the processed and feature-engineered dataset.\n",
    "\n",
    "Dataset:\n",
    "- Processed datasets: `train.csv` and `test.csv`\n",
    "\n",
    "- Features include demographic, transaction, card type, and engineered variables.\n",
    "\n",
    "- Categorical variables are already handled in the data cleaning stage.\n",
    "\n",
    "Workflow – Model Training:\n",
    "1. Load Data\n",
    "- Load `train.csv` and `test.csv`\n",
    "- Separate features (`X`) and target (`y`)\n",
    "\n",
    "2. Handle Class Imbalance\n",
    "- Apply SMOTE on the training set to balance the minority class.\n",
    "\n",
    "3. Train Classification Models\n",
    "- Train at least two models:\n",
    "  - Logistic Regression (baseline linear model)\n",
    "  - Random Forest\n",
    "  - XGBoost (gradient boosting model to capture non-linearities and interactions)\n",
    "- Perform hyperparameter tuning and cross-validation to optimize each model.\n",
    "\n",
    "Next Steps:\n",
    "- The trained models will be saved and later evaluated in a separate notebook using metrics such as accuracy, precision, recall, F1-score, ROC-AUC, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths to the saved CSVs\n",
    "train_path = r'..\\..\\data\\processed\\train.csv'\n",
    "test_path  = r'..\\..\\data\\processed\\test.csv'\n",
    "\n",
    "# Load the CSVs\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "\n",
    "# Split into features and target\n",
    "X_train = train_df.drop(columns=['AttritionFlag'])\n",
    "y_train = train_df['AttritionFlag']\n",
    "\n",
    "X_test  = test_df.drop(columns=['AttritionFlag'])\n",
    "y_test  = test_df['AttritionFlag']\n",
    "\n",
    "# Optional: check shapes\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to training data\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "train_save = X_train_res.copy()\n",
    "train_save['AttritionFlag'] = y_train_res\n",
    "train_save.to_csv(r'..\\..\\data\\processed\\train_after_smote.csv', index=False)\n",
    "\n",
    "# Check the new class distribution\n",
    "print(\"Before SMOTE:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nAfter SMOTE:\")\n",
    "print(y_train_res.value_counts())\n",
    "\n",
    "# Optional: check shapes\n",
    "print(\"\\nX_train_res shape:\", X_train_res.shape)\n",
    "print(\"y_train_res shape:\", y_train_res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Fit scaler on training data and transform both training and test\n",
    "scaler = StandardScaler()\n",
    "X_train_res_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define Logistic Regression\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42, class_weight='balanced')\n",
    "\n",
    "# Hyperparameter candidates\n",
    "param_grid = {'C': [0.1, 1, 10]}\n",
    "\n",
    "# Stratified K-Fold\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Total number of fits\n",
    "total_fits = len(param_grid['C']) * cv.get_n_splits()\n",
    "pbar = tqdm(total=total_fits, desc=\"GridSearchCV Progress\")\n",
    "\n",
    "# Loop through hyperparameters\n",
    "for C_val in param_grid['C']:\n",
    "    lr.set_params(C=C_val)\n",
    "    # Evaluate with cross-validation using scaled features\n",
    "    scores = cross_val_score(lr, X_train_res_scaled, y_train_res, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "    results.append({\n",
    "        'C': C_val,\n",
    "        'mean_cv_roc_auc': np.mean(scores)\n",
    "    })\n",
    "    pbar.update(cv.get_n_splits())  # Update progress bar for each fold set\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# Find best hyperparameter\n",
    "best_result = max(results, key=lambda x: x['mean_cv_roc_auc'])\n",
    "best_lr = LogisticRegression(\n",
    "    C=best_result['C'], solver='lbfgs', max_iter=2000,\n",
    "    random_state=42, class_weight='balanced'\n",
    ")\n",
    "best_lr.fit(X_train_res_scaled, y_train_res)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_result)\n",
    "print(\"Best CV ROC-AUC:\", best_result['mean_cv_roc_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "best_lr = LogisticRegression(C=1, solver='lbfgs', max_iter=2000, random_state=42)\n",
    "best_lr.fit(X_train_res_scaled, y_train_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted probabilities (for ROC-AUC)\n",
    "y_pred_prob = best_lr.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Predicted class labels\n",
    "y_pred = best_lr.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(y_pred_prob, bins=20)\n",
    "plt.title(\"Predicted Probabilities for Churn\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### *Reusable Code for Evaluating Models*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "def evaluate_and_plot(model, X_test, y_test, model_name, save_dir):\n",
    "    \"\"\"\n",
    "    Evaluate a classification model and save a confusion matrix heatmap.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: trained sklearn/xgboost model\n",
    "    - X_test: test features\n",
    "    - y_test: true labels\n",
    "    - model_name: string (e.g. \"Logistic Regression\", \"Random Forest\")\n",
    "    - save_dir: directory path to save the heatmap\n",
    "    \"\"\"\n",
    "    \n",
    "    # Predict labels\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"=== {model_name} ===\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-score:  {f1:.4f}\")\n",
    "    print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    # Ensure save path exists\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Plot confusion matrix heatmap\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=[\"Predicted 0\", \"Predicted 1\"],\n",
    "                yticklabels=[\"Actual 0\", \"Actual 1\"])\n",
    "    plt.title(f\"Confusion Matrix Heatmap ({model_name})\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "\n",
    "    # Save figure\n",
    "    filename = f\"{model_name.lower().replace(' ', '_')}_conf_matrix.png\"\n",
    "    plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_plot(best_lr, X_test_scaled, y_test, \"Logistic Regression\", save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Logistic Regression Model Evaluation — Summary\n",
    "\n",
    "**Test Results:**\n",
    "- **Accuracy:** 95.04% (misleading due to imbalance)\n",
    "- **Precision / Recall / F1-score:** 0.0 (model never predicted churn)\n",
    "- **ROC-AUC:** 0.5088 (almost random performance)\n",
    "\n",
    "**Key Takeaway:**  \n",
    "High accuracy here is misleading since the model completely fails to detect churn and has no meaningful predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------\n",
    "# Define Random Forest\n",
    "# ----------------------\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,        # number of trees\n",
    "    random_state=42,\n",
    "    class_weight='balanced', # handle imbalanced training data\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ----------------------\n",
    "# Hyperparameter candidates\n",
    "# ----------------------\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Stratified K-Fold\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Total number of fits for progress bar\n",
    "total_fits = len(param_grid['max_depth']) * len(param_grid['min_samples_split']) * cv.get_n_splits()\n",
    "pbar = tqdm(total=total_fits, desc=\"Random Forest GridSearchCV\")\n",
    "\n",
    "# ----------------------\n",
    "# Loop through hyperparameters\n",
    "# ----------------------\n",
    "for depth in param_grid['max_depth']:\n",
    "    for min_split in param_grid['min_samples_split']:\n",
    "        rf.set_params(max_depth=depth, min_samples_split=min_split)\n",
    "        scores = cross_val_score(rf, X_train_res, y_train_res, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "        results.append({\n",
    "            'max_depth': depth,\n",
    "            'min_samples_split': min_split,\n",
    "            'mean_cv_roc_auc': np.mean(scores)\n",
    "        })\n",
    "        pbar.update(cv.get_n_splits())\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# ----------------------\n",
    "# Find best hyperparameters\n",
    "# ----------------------\n",
    "best_result = max(results, key=lambda x: x['mean_cv_roc_auc'])\n",
    "best_rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=best_result['max_depth'],\n",
    "    min_samples_split=best_result['min_samples_split'],\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1\n",
    ")\n",
    "best_rf.fit(X_train_res, y_train_res)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_result)\n",
    "print(\"Best CV ROC-AUC:\", best_result['mean_cv_roc_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Evaluation\n",
    "evaluate_and_plot(best_rf, X_test_scaled, y_test, \"Random Forest\", save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Random Forest Model Evaluation\n",
    "\n",
    "**Interpretation:**\n",
    "- The model predicts **only the majority class** (non-churn).\n",
    "- High accuracy is misleading.\n",
    "- Precision, Recall, and F1 are all **zero**, meaning no churn cases were identified.\n",
    "- ROC-AUC slightly above 0.5 → performance is almost random.\n",
    "- This indicates **poor predictive power**; features may not strongly correlate with churn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## 4. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------\n",
    "# Define XGBoost Classifier\n",
    "# ----------------------\n",
    "xgb = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=1,   # handle imbalance (can adjust ratio if needed)\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ----------------------\n",
    "# Hyperparameter candidates\n",
    "# ----------------------\n",
    "param_grid = {\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'n_estimators': [100, 200]\n",
    "}\n",
    "\n",
    "# Stratified K-Fold\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Total fits for progress bar\n",
    "total_fits = (\n",
    "    len(param_grid['max_depth']) *\n",
    "    len(param_grid['learning_rate']) *\n",
    "    len(param_grid['n_estimators']) *\n",
    "    cv.get_n_splits()\n",
    ")\n",
    "pbar = tqdm(total=total_fits, desc=\"XGBoost GridSearchCV\")\n",
    "\n",
    "# ----------------------\n",
    "# Loop through hyperparameters\n",
    "# ----------------------\n",
    "for depth in param_grid['max_depth']:\n",
    "    for lr in param_grid['learning_rate']:\n",
    "        for n_est in param_grid['n_estimators']:\n",
    "            xgb.set_params(max_depth=depth, learning_rate=lr, n_estimators=n_est)\n",
    "            scores = cross_val_score(\n",
    "                xgb, X_train_res, y_train_res,\n",
    "                cv=cv, scoring='roc_auc', n_jobs=-1\n",
    "            )\n",
    "            results.append({\n",
    "                'max_depth': depth,\n",
    "                'learning_rate': lr,\n",
    "                'n_estimators': n_est,\n",
    "                'mean_cv_roc_auc': np.mean(scores)\n",
    "            })\n",
    "            pbar.update(cv.get_n_splits())\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# ----------------------\n",
    "# Find best hyperparameters\n",
    "# ----------------------\n",
    "best_result = max(results, key=lambda x: x['mean_cv_roc_auc'])\n",
    "best_xgb = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=1,\n",
    "    n_jobs=-1,\n",
    "    max_depth=best_result['max_depth'],\n",
    "    learning_rate=best_result['learning_rate'],\n",
    "    n_estimators=best_result['n_estimators']\n",
    ")\n",
    "best_xgb.fit(X_train_res, y_train_res)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_result)\n",
    "print(\"Best CV ROC-AUC:\", best_result['mean_cv_roc_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "evaluate_and_plot(best_xgb, X_test_scaled, y_test, \"XGBoost\", save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### XGBoost Results  \n",
    "\n",
    "- **Accuracy ≈ 95%** (misleading due to class imbalance)  \n",
    "- **Precision / Recall / F1-score for churners = 0.0**  \n",
    "- **ROC-AUC ≈ 0.50** — close to random guessing  \n",
    "\n",
    "**Interpretation:**  \n",
    "Despite being a powerful boosting algorithm, **XGBoost performed no better than Logistic Regression or Random Forest**.  \n",
    "It also defaulted to predicting only the majority class (non-churn), failing to capture any meaningful signal from the features.  \n",
    "\n",
    "**Key Takeaway:**  \n",
    "The poor performance confirms that the **dataset itself lacks predictive power** for churn, and that even advanced models like XGBoost cannot overcome this limitation without richer features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "# Project Conclusion: Churn Prediction for Credit Card Holders\n",
    "\n",
    "## Summary of Findings\n",
    "**Logistic Regression**, **Random Forest**, and **XGBoost** models were trained on the dataset with balanced training data (via SMOTE) and tested on the test data.\n",
    "\n",
    "### Model Performances:\n",
    "- **Accuracy**: ~95% (misleading due to class imbalance)\n",
    "- **Precision / Recall / F1-score**: All **0.0** — no churn cases were identified by either model.\n",
    "- **ROC-AUC**: ~0.51–0.52, only slightly better than random guessing.\n",
    "\n",
    "### Interpretation:\n",
    "- Despite feature engineering, tuning hyperparameters, and balancing the training data, both models defaulted to predicting only the majority class (non-churn).\n",
    "- This indicates **no strong predictive signal** in the available features to separate churn from non-churn customers.\n",
    "- High accuracy is purely a result of the majority class dominating the dataset, not actual predictive performance.\n",
    "\n",
    "## Final Conclusion\n",
    "The dataset, in its current form, **does not contain sufficient or relevant features** to build a model that can reliably predict customer attrition/churn.  \n",
    "Future work should focus on **collecting richer, more behaviorally informative features** and possibly **reshaping the problem definition** before applying predictive modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creditcard-env",
   "language": "python",
   "name": "creditcard-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
