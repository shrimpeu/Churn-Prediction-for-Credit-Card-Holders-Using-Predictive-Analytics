{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned dataset saved from the previous step\n",
    "cleaned_data_path = r'..\\..\\data\\processed\\credit_card_attrition_cleaned.csv'\n",
    "df = pd.read_csv(cleaned_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your cleaned dataset\n",
    "df = df.copy()\n",
    "\n",
    "# Ratios\n",
    "df['SpendIncomeRatio'] = df['TotalSpend'] / (df['Income'] + 1e-6)\n",
    "df['TransactionsTenureRatio'] = df['TotalTransactions'] / (df['Tenure'] + 1e-6)\n",
    "df['CreditUsage'] = df['TotalSpend'] / (df['CreditLimit'] + 1e-6)\n",
    "\n",
    "# Differences\n",
    "df['CreditLimitMinusSpend'] = df['CreditLimit'] - df['TotalSpend']\n",
    "df['AgeMinusTenure'] = df['Age'] - df['Tenure']\n",
    "\n",
    "# Multiplications\n",
    "df['AgeTimesTransactions'] = df['Age'] * df['TotalTransactions']\n",
    "df['IncomeTimesTransactions'] = df['Income'] * df['TotalTransactions']\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical columns\n",
    "cat_cols = ['CardType', 'MaritalStatus', 'EducationLevel', 'Country']\n",
    "\n",
    "for col in cat_cols:\n",
    "    churn_rate = df.groupby(col)['AttritionFlag'].mean()\n",
    "    df[col + '_ChurnRate'] = df[col].map(churn_rate)\n",
    "\n",
    "print(df[[col + '_ChurnRate' for col in cat_cols]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_for_cluster = df.select_dtypes(include=['number']).drop(columns=['AttritionFlag'])\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(num_for_cluster)\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
    "df['Cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "print(df.groupby('Cluster')['AttritionFlag'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Set up the figure\n",
    "plt.figure(figsize=(21, 16))\n",
    "\n",
    "# Create a heatmap for the correlation matrix\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', cbar=True, center=0, linewidths=0.5)\n",
    "\n",
    "# Add title\n",
    "plt.title('Correlation Heatmap', fontsize=16)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,16))\n",
    "sns.heatmap(correlation_matrix, cmap='coolwarm', center=0, linewidths=0.5)\n",
    "plt.title('Spearman Correlation Matrix')\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df0 = df.copy()\n",
    "target = 'AttritionFlag'\n",
    "\n",
    "X_full = df0.drop(columns=[target])  # keep ID out of features\n",
    "y_full = df0[target].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_full, y_full, test_size=0.2, random_state=42, stratify=y_full\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# =====================\n",
    "# 1. Features & Target\n",
    "# =====================\n",
    "target_col = 'AttritionFlag'\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# =====================\n",
    "# 2. Leakage-safe split\n",
    "# =====================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# =====================\n",
    "# 3. Train Model\n",
    "# =====================\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# =====================\n",
    "# 4. Evaluate\n",
    "# =====================\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nROC-AUC Score:\", roc_auc_score(y_test, y_pred_proba))\n",
    "\n",
    "# =====================\n",
    "# 5. Feature Importance\n",
    "# =====================\n",
    "importances = pd.Series(xgb_model.feature_importances_, index=X_train.columns)\n",
    "print(\"\\nTop 10 features:\\n\", importances.sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creditcard-env",
   "language": "python",
   "name": "creditcard-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
